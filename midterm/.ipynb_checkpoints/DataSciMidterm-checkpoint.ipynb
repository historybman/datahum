{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm exam\n",
    "\n",
    "This exam is open-notebook and open-web. It's also open-instructor, in the coding sections of the exam; if you run into a bug that you can't explain after a few tries, I'm willing to take a look at your code.\n",
    "\n",
    "We start with three short essay questions, each of which can be answered in a paragraph or so. The first two paragraphs can be pretty brief. The third one might run a bit longer, or might become two paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short essay questions.\n",
    "\n",
    "#### 1. Overfitting.\n",
    "\n",
    "What is \"overfitting\"? And why is this problem especially likely to arise when we model unstructured datasets (for instance, a collection of tweets or novels, rather than a simple table with five or six columns)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for 1:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cross-validation.\n",
    "\n",
    "What does it mean to cross-validate a model? What's the point of doing this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Interpreting models of the human past.\n",
    "\n",
    "Beyond general quantitative pitfalls like \"overfitting,\" why does it become challenging to draw historical and cultural conclusions from a quantitative model?\n",
    "\n",
    "Choose any (single) article from the set we discussed in the week of March 12, and explain why the interpretive problems it confronts emerge specifically from the complexity of the human subject-matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Surviving the *Titanic.*\n",
    "\n",
    "We have good records about the passengers who were aboard the *Titanic* when it sank in 1912. (The provenance of the data is difficult to track, but I think this particular form of the dataset comes from [a Kaggle machine learning competition.](https://www.kaggle.com/c/titanic))\n",
    "\n",
    "Let's use a sample of the data to rehearse methods of exploratory data analysis in Pandas.\n",
    "\n",
    "First, read in the dataset (```titanic.csv```). What do you have?\n",
    "\n",
    "The dataset has twelve columns, but here are some important or perplexing ones:\n",
    "\n",
    "    **Survived**: A value of 1 indicates that the passenger survived. 0, didn't.\n",
    "    **Pclass**: Did the passenger buy a 1st, 2nd, or 3rd-class ticket?\n",
    "    **Sex**: Is coded as \"male\" or \"female.\" This may really be \"gender,\" since I doubt that ticket agents checked the passengers' biological sex in 1912, but we'll let that pass.\n",
    "    **Age**: In years.\n",
    "    **Embarked**: Which port the passenger sailed from.\n",
    "    **Sibsp**: How many siblings or spouses the passenger had on board.\n",
    "    **Parch**: How many parents or children the passenger had on board.\n",
    "\n",
    "Let's start by answering some simple questions.\n",
    "\n",
    "#### 1. What percentage of passengers survived, overall?\n",
    "#### 2. What was the gender balance, overall, among passengers? Say, what fraction were women?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset, and use the ```.head()``` method to glance at the first few rows.\n",
    "\n",
    "# Here are a few module imports to get you started.\n",
    "\n",
    "import os, math\n",
    "# you won't need math right here, but we will need it later on\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Some code is needed here, to read in the data.\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here to calculate (1) the fraction of passengers who survived, and (2) the fraction who were women.\n",
    "import numpy as np\n",
    "by_survived = titanic.groupby('Survived')\n",
    "sum_survived = by_survived.count()['Name']\n",
    "sum_survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Now let's make that slightly more complex. Did the passengers really follow a policy of \"women and children first\"?\n",
    "\n",
    "Let's start answer that by producing a bar graph that indicates how the probability of survival varied across Sex. In other words, we want to have one bar that indicates the probability of survival for men (not the raw number of men surviving but the *fraction* who survived), and a second bar indicating the probability for women.\n",
    "\n",
    "You can use the split-apply-combine method from week 3 to summarize the data. Note that simply averaging (taking the mean) across a column that is either 0 or 1 will in effect give you the probability of finding a 1 in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (3): Code is needed here to split-apply-combine,\n",
    "# and then produce a bar graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. One final twist.\n",
    "\n",
    "What about the relationship of \"ticket class\" to survival? And how did that interact with gender?\n",
    "\n",
    "See if you can produce a visualization that plots probability of survival broken out by Pclass and Sex at the same time. For instance, it could take the form of two lines (one for men and one for women), with the y axis indicating probability of survival, and the x axis indicating ticket class (1, 2, or 3). It's also possible to achieve the same thing with a bar graph (using paired bars). We did a version of that in week 3. Either solution is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## (4): Code is needed here to produce a visualization that\n",
    "## reveals probability of survival broken out by Pclass\n",
    "## and Sex at the same time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ham or spam?\n",
    "\n",
    "Now let's move to predictive modeling of less structured data.\n",
    "\n",
    "#### Part 1.\n",
    "\n",
    "I've provided you with part of [a spam dataset developed by Almeida et al.](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/) Each row in this dataset contains an SMS message. 747 of them were flagged by users as \"spam,\" and 747 are legitimate--for our purposes, \"ham.\" (In case this etymology is vanishing in the mists of time: spam was originally a kind of canned meat.)\n",
    "\n",
    "There are two columns in the dataset. **Category** contains a flag indicating whether the message is spam; **text** contains the raw text of the message itself.\n",
    "\n",
    "Your first goals are to:\n",
    "\n",
    "1. Read this dataset (```hamorspam.csv```) in as a pandas DataFrame, and create a new column ```isspam```, which contains 1 if the row is spam, and 0 otherwise.\n",
    "\n",
    "2. Create a termdoc matrix based on the top 1000 words in the dataset. Use the ```.head()``` method to print out a few rows.\n",
    "\n",
    "3. Import multinomial Naive Bayes amd cross_val_score from sklearn; then do five-fold crossvalidation to estimate the accuracy of multinomial Naive Bayes on this dataset.\n",
    "\n",
    "Try to do each of those things in a separate cell of this notebook. The homework solution from week 6 (Feb 19-25) should be a useful guide here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (1): Read in hamorspam.csv; create a numeric column \"isspam.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (2): Create a termdoc matrix. There are several ways to do this, but CountVectorizer\n",
    "# will save you some work.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (3): Import Multinomial Naive Bayes and cross_val_score;\n",
    "# estimate the predictive accuracy of Naive Bayes, using\n",
    "# five-fold crossvalidation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One final question.** By the way, one of the things I did to prepare this data for you was to rebalance it so that there were even numbers of \"spam\" and \"ham\" messages. I did this because we've practiced cross-validation using a simple accuracy measure that doesn't distinguish between \"precision\" and \"recall.\" \n",
    "\n",
    "In the original data set, there were 4,827 ham and 747 spam messages. Why might simple \"accuracy\" be an unreliable way of evaluating a model on an unbalanced dataset like this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for part (4): Briefly explain why \"accuracy\" alone isn't an entirely trustworthy measure on unbalanced datasets:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ham or spam? Part 2.\n",
    "\n",
    "Good old Naive Bayes is strikingly accurate on this task. How is that possible? What words provided the key clues here?\n",
    "\n",
    "There are several ways to answer that question. One way we haven't practiced yet--but that you should know about--is to fit a scikit-learn model, and then use the ```.coef_``` attribute of the model to extract the coefficients that the model itself actually used. The list of numbers will look opaque, but these numbers can be paired with features (the columns in the termdoc matrix you used). For instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.29443906, -6.29113695, -7.49510975, ..., -9.69233433,\n",
       "        -9.69233433, -3.07493135]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code is purely illustrative; it doesn't need to run in\n",
    "# your notebook (and probably won't).\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(termdoc.as_matrix(), hamorspam['isspam'])\n",
    "mnb.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we haven't practiced that method, and it's good to have multiple ways of solving a problem. So let's use a method we *have* practiced — Dunning's log likelihood. This is a straightforward way of measuring how much the distribution of a word across two corpora diverges from its EXPECTED frequency -- i.e., the frequency it would have if it were equally distributed over both corpora.\n",
    "\n",
    "Use Dunning's log likelihood to find the ten words most overrepresented in spam, and the ten words most overrepresented in ham.\n",
    "\n",
    "The notebooks for week 4 of the course (\"Representing language geometrically\") could be helpful here, but note that they began by counting words in a different way than we have done above. In week 4, we hadn't introduced the CountVectorizer, so we had to manually create a Counter for each class, holding the number of occurrences for each word.\n",
    "\n",
    "If possible, avoid repeating all the word-counting operations on the ham and spam datasets. Instead, use the term-doc dataframe you already created with the CountVectorizer, and extract the information you need for the signed_dunnings function from that dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I have copied a couple of functions you might need from the week 4 notebooks.\n",
    "\n",
    "def signed_dunnings(countsA, totalA, countsB, totalB, word):\n",
    "    ''' This function calculates a signed (+1 / -1)\n",
    "    version of Dunning's log likelihood, for a single word (provided in\n",
    "    the argument \"word\").\n",
    "    \n",
    "    Intuitively, Dunnings log likelihood is a number \n",
    "    that gets larger as the frequencies of the word in our two corpora\n",
    "    diverge from their EXPECTED values -- i.e., the frequencies we would\n",
    "    see if the word were equally distributed. But the Dunnings value also\n",
    "    tends to get larger as the overall frequency of the word increases.\n",
    "    \n",
    "    CountsA and countsB are Counters for the two different corpora, where\n",
    "    keys are words and the values are the # of occurrences of that word\n",
    "    in the corpus.\n",
    "    \n",
    "    This function also requires two additional arguments:\n",
    "    the total number of words in corpus A and corpus B. \n",
    "    \n",
    "    We could calculate those totals inside the function,\n",
    "    but it's faster to calculate them just once, outside the function.\n",
    "    \n",
    "    Also note: the strict definition of Dunnings has no 'sign': it gets bigger\n",
    "    whether a word is overrepresented in A or B. I've edited that so that Dunnings\n",
    "    is positive if overrepresented in A, and negative if overrepresented in B.\n",
    "    '''\n",
    "    \n",
    "    if word not in countsA and word not in countsB:\n",
    "        return 0\n",
    "    \n",
    "    # the raw frequencies of this word in our two corpora\n",
    "    # still doing a little Laplacian smoothing here\n",
    "    a = countsA[word] + 0.1\n",
    "    b = countsB[word] + 0.1\n",
    "    \n",
    "    # now let's calculate the expected number of times this\n",
    "    # word would occur in both if the frequency were constant\n",
    "    # across both\n",
    "    overallfreq = (a + b) / (totalA + totalB)\n",
    "    expectedA = totalA * overallfreq\n",
    "    expectedB = totalB * overallfreq\n",
    "    \n",
    "    # and now the Dunning's formula\n",
    "    dunning = 2 * ((a * math.log(a / expectedA)) + (b * math.log(b / expectedB)))\n",
    "    \n",
    "    if math.isnan(dunning):\n",
    "        print(a, totalA, b, totalB)\n",
    "        user = input('Division by zero error. Are the values above what you expected?')\n",
    "    \n",
    "    if a < expectedA:\n",
    "        return -dunning\n",
    "    else:   \n",
    "        return dunning\n",
    "\n",
    "def headandtail(tuplelist, n):\n",
    "    ''' Returns the top n and bottom n values\n",
    "    in a list of two-tuples, where the first\n",
    "    value of each tuple is numeric.\n",
    "    '''\n",
    "    \n",
    "    tuplelist.sort(reverse = True)\n",
    "    print(\"TOP VALUES:\")\n",
    "    for i in range(n):\n",
    "        print(tuplelist[i][1], tuplelist[i][0])\n",
    "    \n",
    "    print()\n",
    "    print(\"BOTTOM VALUES:\")\n",
    "    lastindex = len(tuplelist) - 1\n",
    "    for i in range(lastindex, lastindex - n, -1):\n",
    "        print(tuplelist[i][1], tuplelist[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here insert your own code to translate the termdoc data frame\n",
    "# produced by CountVectorizer into the different data structures\n",
    "# expected by our signed_dunnings function.\n",
    "\n",
    "# Then loop through all the words in our termdoc data frame,\n",
    "# getting the Dunnings value for each word. Finally, report\n",
    "# the top and bottom 10 words (most common in spam, most\n",
    "# common in ham).\n",
    "\n",
    "# First, a couple of imports you might need:\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
