{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: A Naive Bayes classifier\n",
    "\n",
    "Suppose President Trump gets savvy, and realizes that people can use the Android/iPhone distinction to separate his tweets from the the tweets of aides. He starts using an iPhone too. Now, how will we distinguish tweets really authored by the President?\n",
    "\n",
    "Well, one thing we can do is train a classifier to predict authorship using the text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/rmorriss/Documents/datahum/code\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSN</th>\n",
       "      <th>created</th>\n",
       "      <th>truncated</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>id</th>\n",
       "      <th>replyToUID</th>\n",
       "      <th>statusSource</th>\n",
       "      <th>screenName</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>My economic policy speech will be carried live...</td>\n",
       "      <td>False</td>\n",
       "      <td>9214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-08 15:20:44</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762669882571980801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>3107</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Join me in Fayetteville, North Carolina tomorr...</td>\n",
       "      <td>False</td>\n",
       "      <td>6981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-08 13:28:20</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762641595439190016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>2390</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>#ICYMI: \"Will Media Apologize to Trump?\" https...</td>\n",
       "      <td>False</td>\n",
       "      <td>15724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-08 00:05:54</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762439658911338496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>6691</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Michael Morell, the lightweight former Acting ...</td>\n",
       "      <td>False</td>\n",
       "      <td>19837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-07 23:09:08</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762425371874557952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>6402</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>The media is going crazy. They totally distort...</td>\n",
       "      <td>False</td>\n",
       "      <td>34051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-07 21:31:46</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762400869858115588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>11717</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             1   \n",
       "1           1             2   \n",
       "2           2             3   \n",
       "3           3             4   \n",
       "4           4             5   \n",
       "\n",
       "                                                text favorited  favoriteCount  \\\n",
       "0  My economic policy speech will be carried live...     False           9214   \n",
       "1  Join me in Fayetteville, North Carolina tomorr...     False           6981   \n",
       "2  #ICYMI: \"Will Media Apologize to Trump?\" https...     False          15724   \n",
       "3  Michael Morell, the lightweight former Acting ...     False          19837   \n",
       "4  The media is going crazy. They totally distort...     False          34051   \n",
       "\n",
       "  replyToSN              created truncated  replyToSID                  id  \\\n",
       "0       NaN  2016-08-08 15:20:44     False         NaN  762669882571980801   \n",
       "1       NaN  2016-08-08 13:28:20     False         NaN  762641595439190016   \n",
       "2       NaN  2016-08-08 00:05:54     False         NaN  762439658911338496   \n",
       "3       NaN  2016-08-07 23:09:08     False         NaN  762425371874557952   \n",
       "4       NaN  2016-08-07 21:31:46     False         NaN  762400869858115588   \n",
       "\n",
       "   replyToUID                                       statusSource  \\\n",
       "0         NaN  <a href=\"http://twitter.com/download/android\" ...   \n",
       "1         NaN  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2         NaN  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3         NaN  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4         NaN  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "        screenName  retweetCount isRetweet retweeted  longitude  latitude  \n",
       "0  realDonaldTrump          3107     False     False        NaN       NaN  \n",
       "1  realDonaldTrump          2390     False     False        NaN       NaN  \n",
       "2  realDonaldTrump          6691     False     False        NaN       NaN  \n",
       "3  realDonaldTrump          6402     False     False        NaN       NaN  \n",
       "4  realDonaldTrump         11717     False     False        NaN       NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, csv, math, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print('Current working directory: ' + cwd + '\\n')\n",
    "      \n",
    "relativepath = os.path.join('..', 'data', 'weekfour', 'trump.csv')\n",
    "trump = pd.read_csv(relativepath)\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simplify the Trump dataframe. We only need three columns:\n",
    "\n",
    "1. Text of the tweet\n",
    "2. Source = Android or iphone\n",
    "3. A random number 0-4 that we'll use to divide the dataset into five 'folds'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My economic policy speech will be carried live...</td>\n",
       "      <td>android</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Join me in Fayetteville, North Carolina tomorr...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#ICYMI: \"Will Media Apologize to Trump?\" https...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Morell, the lightweight former Acting ...</td>\n",
       "      <td>android</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The media is going crazy. They totally distort...</td>\n",
       "      <td>android</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   source  fold\n",
       "0  My economic policy speech will be carried live...  android     0\n",
       "1  Join me in Fayetteville, North Carolina tomorr...   iphone     2\n",
       "2  #ICYMI: \"Will Media Apologize to Trump?\" https...   iphone     0\n",
       "3  Michael Morell, the lightweight former Acting ...  android     3\n",
       "4  The media is going crazy. They totally distort...  android     3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trump_test(a_data_frame, rowidx):\n",
    "    if 'iphone' in a_data_frame['statusSource'][rowidx]:\n",
    "        return 'iphone'\n",
    "    elif 'android' in a_data_frame['statusSource'][rowidx]:\n",
    "        return 'android'\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "tweet_text = trump['text']\n",
    "\n",
    "source = []\n",
    "fold = []\n",
    "for idx in trump.index:\n",
    "    source.append(trump_test(trump, idx))\n",
    "    fold.append(random.sample(list(range(5)), 1)[0])\n",
    "source = pd.Series(source, index = trump.index)\n",
    "fold = pd.Series(fold, index = trump.index)\n",
    "\n",
    "tdf = pd.concat([tweet_text, source, fold], axis = 1)\n",
    "tdf.columns = ['text', 'source', 'fold']\n",
    "\n",
    "# limit the dataframe to columns with either android or iphone;\n",
    "# exclude 'other'\n",
    "tdf = tdf[(tdf['source'] == 'android') | (tdf['source'] == 'iphone')]\n",
    "tdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to divide the dataset into a training set and a test set. This is easily done using the \"folds.\" We select one fold as our test set and use all the others as a training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set includes 1097\n",
      "Test set includes 293\n"
     ]
    }
   ],
   "source": [
    "testset = tdf[tdf['fold'] == 4]\n",
    "trainingset = tdf[tdf['fold'] != 4]\n",
    "print('Training set includes ' + str(trainingset.shape[0]))\n",
    "print('Test set includes ' + str(testset.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need some basic text-wrangling functions that we've used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(astring):\n",
    "    ''' Breaks a string into words, and counts them.\n",
    "    Designed so it strips punctuation and lowercases everything,\n",
    "    but doesn't separate hashtags and at-signs.\n",
    "    '''\n",
    "    wordcounts = Counter()\n",
    "    # create a counter to hold the counts\n",
    "    \n",
    "    tokens = astring.split()\n",
    "    for t in tokens:\n",
    "        word = t.strip(',.!?:;-â€”()<>[]/\"\\'').lower()\n",
    "        wordcounts[word] += 1\n",
    "        \n",
    "    return wordcounts\n",
    "\n",
    "def create_vocab(seq_of_strings, n):\n",
    "    ''' Given a sequence of text snippets, this function\n",
    "    returns the n most common words. We'll use this to\n",
    "    create a limited 'vocabulary'.\n",
    "    '''\n",
    "    vocab = Counter()\n",
    "    for astring in seq_of_strings:\n",
    "        counts = tokenize(astring)\n",
    "        vocab = vocab + counts\n",
    "    topn = [x[0] for x in vocab.most_common(n)]\n",
    "    return topn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can actually write functions that build a Naive Bayes model. ```train_nb_model``` is the central function here. It calls the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "android    598\n",
      "iphone     499\n",
      "Name: text, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>all_prob</th>\n",
       "      <th>neg_prob</th>\n",
       "      <th>pos_prob</th>\n",
       "      <th>neg_norm</th>\n",
       "      <th>pos_norm</th>\n",
       "      <th>log_neg</th>\n",
       "      <th>log_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>160</td>\n",
       "      <td>486</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.022287</td>\n",
       "      <td>0.038614</td>\n",
       "      <td>0.681899</td>\n",
       "      <td>1.181443</td>\n",
       "      <td>-0.382873</td>\n",
       "      <td>0.166737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>132</td>\n",
       "      <td>243</td>\n",
       "      <td>0.018973</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.019307</td>\n",
       "      <td>0.969115</td>\n",
       "      <td>1.017616</td>\n",
       "      <td>-0.031372</td>\n",
       "      <td>0.017463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>79</td>\n",
       "      <td>289</td>\n",
       "      <td>0.018619</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.022962</td>\n",
       "      <td>0.591034</td>\n",
       "      <td>1.233273</td>\n",
       "      <td>-0.525882</td>\n",
       "      <td>0.209671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>126</td>\n",
       "      <td>188</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>1.104775</td>\n",
       "      <td>0.940237</td>\n",
       "      <td>0.099642</td>\n",
       "      <td>-0.061623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>95</td>\n",
       "      <td>209</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.860365</td>\n",
       "      <td>1.079647</td>\n",
       "      <td>-0.150398</td>\n",
       "      <td>0.076634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg  pos  all_prob  neg_prob  pos_prob  neg_norm  pos_norm   log_neg  \\\n",
       "the  160  486  0.032684  0.022287  0.038614  0.681899  1.181443 -0.382873   \n",
       "to   132  243  0.018973  0.018387  0.019307  0.969115  1.017616 -0.031372   \n",
       "and   79  289  0.018619  0.011004  0.022962  0.591034  1.233273 -0.525882   \n",
       "in   126  188  0.015887  0.017551  0.014937  1.104775  0.940237  0.099642   \n",
       "a     95  209  0.015381  0.013233  0.016606  0.860365  1.079647 -0.150398   \n",
       "\n",
       "      log_pos  \n",
       "the  0.166737  \n",
       "to   0.017463  \n",
       "and  0.209671  \n",
       "in  -0.061623  \n",
       "a    0.076634  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize(df, rowidx):\n",
    "    if df.loc[rowidx, 'source'] == 'android':\n",
    "        return 'positive'\n",
    "    elif df.loc[rowidx, 'source'] == 'iphone':\n",
    "        return 'negative'\n",
    "    else:\n",
    "        print('error: neither iphone nor android')\n",
    "        return 'other'\n",
    "\n",
    "def get_priors(df):\n",
    "    source_counts = df.groupby('source').count()['text']\n",
    "    print(source_counts)\n",
    "    positive_odds = source_counts['android'] / source_counts['iphone']\n",
    "    negative_odds = source_counts['iphone'] / source_counts['android']\n",
    "    return math.log(positive_odds), math.log(negative_odds)\n",
    "\n",
    "def train_nb_model(df, p):\n",
    "    vocab = create_vocab(df['text'], p)\n",
    "    vocabset = set(vocab)\n",
    "    # we make a set because membership-checking is faster\n",
    "    # in sets; but we also hold onto the list, which is ordered\n",
    "    \n",
    "    positive_prior, negative_prior = get_priors(df)\n",
    "    \n",
    "    positive_counts = Counter()\n",
    "    negative_counts = Counter()\n",
    "    \n",
    "    for i in df.index:\n",
    "        tweet = df['text'][i]\n",
    "        tweet_counts = tokenize(tweet)\n",
    "        category = categorize(df, i)\n",
    "        if category == 'negative':\n",
    "            negative_counts = negative_counts + tweet_counts\n",
    "        elif category == 'positive':\n",
    "            positive_counts = positive_counts + tweet_counts\n",
    "    \n",
    "    # Now let's organize these Counters into a DataFrame\n",
    "    \n",
    "    negative = pd.Series(1, index = vocab)\n",
    "    positive = pd.Series(1, index = vocab)\n",
    "    # notice initializing to 1 -- Laplacian smoothing\n",
    "    \n",
    "    for word, count in positive_counts.items():\n",
    "        if word in vocabset:\n",
    "            positive[word] += count\n",
    "    \n",
    "    for word, count in negative_counts.items():\n",
    "        if word in vocabset:\n",
    "            negative[word] += count\n",
    "    \n",
    "    all_prob = (negative + positive) / (np.sum(negative) + np.sum(positive))\n",
    "    \n",
    "    negative_prob = negative / np.sum(negative)\n",
    "    positive_prob = positive / np.sum(positive)\n",
    "    \n",
    "    # note that when we sum up the negative and positive\n",
    "    # columns, we are also summing up all the Laplacian 1's\n",
    "    # we initially added to them\n",
    "    \n",
    "    model = pd.concat([negative, positive, all_prob, \n",
    "                       negative_prob, positive_prob], axis = 1) \n",
    "        \n",
    "    model.columns = ['neg', 'pos', 'all_prob', 'neg_prob', 'pos_prob']\n",
    "    \n",
    "    # The next step is unnecessary, and will not be found in\n",
    "    # most published versions of naive Bayes. I'm providing it\n",
    "    # because it may help you understand the logic of the\n",
    "    # algorithm.\n",
    "    \n",
    "    model['neg_norm'] = negative_prob / all_prob\n",
    "    model['pos_norm'] = positive_prob / all_prob\n",
    "    \n",
    "    \n",
    "    model['log_neg'] = [math.log(x) for x in model['neg_norm']]\n",
    "    model['log_pos'] = [math.log(x) for x in model['pos_norm']]\n",
    "    return vocab, positive_prior, negative_prior, model\n",
    "\n",
    "vocab, positive_prior, negative_prior, model = train_nb_model(trainingset, 1500)\n",
    "model.head() \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we're using logarithms of the probabilities, so that we can just add them up. Our priors are logarithms, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18098465819911314 -0.18098465819911305\n"
     ]
    }
   ],
   "source": [
    "print(positive_prior, negative_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a function that applies a given model to a given testset. It will have lots of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 239 rows right, and 54 wrong.\n",
      "Accuracy was 81.57%\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def apply_model(vocab, positive_prior, negative_prior, model, testset):\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    vocabset = set(vocab)\n",
    "    odds_pos = []\n",
    "    odds_neg = []\n",
    "\n",
    "    for i in testset.index:\n",
    "        odds_positive = positive_prior\n",
    "        odds_negative = negative_prior\n",
    "        tweet = testset['text'][i]\n",
    "        tweet_counts = tokenize(tweet)\n",
    "        for word, count in tweet_counts.items():\n",
    "            if word not in vocabset:\n",
    "                continue\n",
    "            odds_positive += model.loc[word, 'log_pos']\n",
    "            odds_negative += model.loc[word, 'log_neg']\n",
    "            \n",
    "        if odds_positive > odds_negative:\n",
    "            prediction = 'positive'\n",
    "        else:\n",
    "            prediction = 'negative'\n",
    "        \n",
    "        odds_pos.append(odds_positive)\n",
    "        odds_neg.append(odds_negative)\n",
    "\n",
    "        reality = categorize(testset, i)\n",
    "        if reality != 'positive' and reality != 'negative':\n",
    "            continue\n",
    "        elif prediction == reality:\n",
    "            right += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "    print(\"Got \" + str(right) + \" rows right, and \" + str(wrong) + \" wrong.\")\n",
    "    accuracy = (right / (wrong + right)) * 100\n",
    "    print(\"Accuracy was {0:.2f}%\".format(accuracy))\n",
    "    \n",
    "    resultset = testset.copy()\n",
    "    resultset['odds_positive'] = odds_pos\n",
    "    resultset['odds_negative'] = odds_neg\n",
    "    resultset = resultset.sort_values(by = 'odds_positive')\n",
    "    \n",
    "    return resultset, accuracy\n",
    "\n",
    "newtestset, accuracy = apply_model(vocab, positive_prior, \n",
    "                         negative_prior, model, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```apply_model``` function returns a version of the test set with two new columns. The dataframe is sorted by the (ascending) odds of being in the positive class, so we can find the \"Trumpiest\" and \"least Trumpy\" tweets by saying ```.tail()``` or ```.head()``` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>fold</th>\n",
       "      <th>odds_positive</th>\n",
       "      <th>odds_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>\"Little\" Michael Bloomberg, who never had the ...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.342857</td>\n",
       "      <td>-5.525900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>I have raised/given a tremendous amount of mon...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.367067</td>\n",
       "      <td>-5.554729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Many people are equating BREXIT, and what is g...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.385317</td>\n",
       "      <td>-6.427663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Wow, Lyin' Ted Cruz really went wacko today. M...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.388304</td>\n",
       "      <td>-7.871770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Hillary Clinton is unfit to be president. She ...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.406628</td>\n",
       "      <td>-5.365968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>\"@FrankDallasAgg: @megynkelly @realDonaldTrump...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.433751</td>\n",
       "      <td>-8.140402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>We are TRYING to fight ISIS, and now our own p...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.472093</td>\n",
       "      <td>-6.110735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>I am \"the king of debt.\"That has been great fo...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.497105</td>\n",
       "      <td>-7.033512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Crooked Hillary Clinton looks presidential? I ...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.609593</td>\n",
       "      <td>-7.447627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>If Cory Booker is the future of the Democratic...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>4</td>\n",
       "      <td>2.627192</td>\n",
       "      <td>-6.973521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>.@FoxNews is much better, and far more truthfu...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.631413</td>\n",
       "      <td>-7.030388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>The Democrats are in a total meltdown but the ...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.635662</td>\n",
       "      <td>-7.984781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I am not just running against Crooked Hillary ...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.727363</td>\n",
       "      <td>-6.835248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>Wow, President Obama just landed in Cuba, a bi...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.761179</td>\n",
       "      <td>-6.543336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>George Will, one of the most overrated politic...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>2.987626</td>\n",
       "      <td>-8.666143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>I have millions more votes/hundreds more dels ...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>3.079950</td>\n",
       "      <td>-8.202372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>President Obama looks and sounds so ridiculous...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>3.121934</td>\n",
       "      <td>-8.507830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>I would rather run against Crooked Hillary Cli...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>3.445715</td>\n",
       "      <td>-8.897557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>I would have had many millions of votes more t...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>3.505784</td>\n",
       "      <td>-8.966038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>Ted Cruz didn't win Iowa, he stole it. That is...</td>\n",
       "      <td>android</td>\n",
       "      <td>4</td>\n",
       "      <td>4.353897</td>\n",
       "      <td>-11.727286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   source  fold  \\\n",
       "108   \"Little\" Michael Bloomberg, who never had the ...  android     4   \n",
       "635   I have raised/given a tremendous amount of mon...  android     4   \n",
       "451   Many people are equating BREXIT, and what is g...  android     4   \n",
       "869   Wow, Lyin' Ted Cruz really went wacko today. M...  android     4   \n",
       "596   Hillary Clinton is unfit to be president. She ...  android     4   \n",
       "761   \"@FrankDallasAgg: @megynkelly @realDonaldTrump...  android     4   \n",
       "264   We are TRYING to fight ISIS, and now our own p...  android     4   \n",
       "476   I am \"the king of debt.\"That has been great fo...  android     4   \n",
       "720   Crooked Hillary Clinton looks presidential? I ...  android     4   \n",
       "172   If Cory Booker is the future of the Democratic...   iphone     4   \n",
       "267   .@FoxNews is much better, and far more truthfu...  android     4   \n",
       "185   The Democrats are in a total meltdown but the ...  android     4   \n",
       "8     I am not just running against Crooked Hillary ...  android     4   \n",
       "1146  Wow, President Obama just landed in Cuba, a bi...  android     4   \n",
       "438   George Will, one of the most overrated politic...  android     4   \n",
       "1094  I have millions more votes/hundreds more dels ...  android     4   \n",
       "1142  President Obama looks and sounds so ridiculous...  android     4   \n",
       "863   I would rather run against Crooked Hillary Cli...  android     4   \n",
       "563   I would have had many millions of votes more t...  android     4   \n",
       "1443  Ted Cruz didn't win Iowa, he stole it. That is...  android     4   \n",
       "\n",
       "      odds_positive  odds_negative  \n",
       "108        2.342857      -5.525900  \n",
       "635        2.367067      -5.554729  \n",
       "451        2.385317      -6.427663  \n",
       "869        2.388304      -7.871770  \n",
       "596        2.406628      -5.365968  \n",
       "761        2.433751      -8.140402  \n",
       "264        2.472093      -6.110735  \n",
       "476        2.497105      -7.033512  \n",
       "720        2.609593      -7.447627  \n",
       "172        2.627192      -6.973521  \n",
       "267        2.631413      -7.030388  \n",
       "185        2.635662      -7.984781  \n",
       "8          2.727363      -6.835248  \n",
       "1146       2.761179      -6.543336  \n",
       "438        2.987626      -8.666143  \n",
       "1094       3.079950      -8.202372  \n",
       "1142       3.121934      -8.507830  \n",
       "863        3.445715      -8.897557  \n",
       "563        3.505784      -8.966038  \n",
       "1443       4.353897     -11.727286  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtestset.tail(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.\n",
    "\n",
    "To start with, just play around with the functions above in order to find a value of ```p``` (number of parameters in the model) that roughly maximizes accuracy on the test set.\n",
    "\n",
    "What accuracy do you get if you train a model on the whole ```tdf``` data frame, and also apply it to ```tdf``` as a whole?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "android    762\n",
      "iphone     628\n",
      "Name: text, dtype: int64\n",
      "Got 1248 rows right, and 142 wrong.\n",
      "Accuracy was 89.78%\n"
     ]
    }
   ],
   "source": [
    "vocab, positive_prior, negative_prior, model = train_nb_model(tdf, 2000)\n",
    "newtestset = apply_model(vocab, positive_prior, negative_prior, model, tdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.\n",
    "\n",
    "Write a function that *cross-validates* a modeling strategy by applying it successively to five different training sets and testing it on five different test sets.\n",
    "\n",
    "This is called \"five-fold crossvalidation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "android    606\n",
      "iphone     504\n",
      "Name: text, dtype: int64\n",
      "Got 227 rows right, and 53 wrong.\n",
      "Accuracy was 81.07%\n",
      "The average accuracy was 81.07142857142857\n",
      "source\n",
      "android    622\n",
      "iphone     509\n",
      "Name: text, dtype: int64\n",
      "Got 202 rows right, and 57 wrong.\n",
      "Accuracy was 77.99%\n",
      "The average accuracy was 79.53185328185327\n",
      "source\n",
      "android    600\n",
      "iphone     488\n",
      "Name: text, dtype: int64\n",
      "Got 237 rows right, and 65 wrong.\n",
      "Accuracy was 78.48%\n",
      "The average accuracy was 79.1801759185865\n",
      "source\n",
      "android    622\n",
      "iphone     512\n",
      "Name: text, dtype: int64\n",
      "Got 208 rows right, and 48 wrong.\n",
      "Accuracy was 81.25%\n",
      "The average accuracy was 79.69763193893988\n",
      "source\n",
      "android    598\n",
      "iphone     499\n",
      "Name: text, dtype: int64\n",
      "Got 239 rows right, and 54 wrong.\n",
      "Accuracy was 81.57%\n",
      "The average accuracy was 80.07209872521334\n"
     ]
    }
   ],
   "source": [
    "def fivefold_crossvalidate(tdf, p):\n",
    "    accuracies = []\n",
    "    for i in range(5):\n",
    "        testset = tdf[tdf['fold'] == i]\n",
    "        trainingset = tdf[tdf['fold'] != i]\n",
    "        vocab, positive_prior, negative_prior, model = train_nb_model(trainingset, p)\n",
    "        newtestset, accuracy = apply_model(vocab, positive_prior, negative_prior, model, testset)\n",
    "        accuracies.append(accuracy)\n",
    "        avg_acc = sum(accuracies)/len(accuracies)\n",
    "        print(\"The average accuracy was \" + str(avg_acc))\n",
    "\n",
    "fivefold_crossvalidate(tdf, 2000)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 (probably, for homework).\n",
    "\n",
    "Do all this for the poefic dataset, trying to distinguish poetry from fiction. Create a new notebook. Copy functions as needed in order to build a naive Bayes classifier and run five-fold crossvalidation.\n",
    "\n",
    "How much accuracy do you get? Why do you think that accuracy is higher or lower than it was on the Trump tweet data? (You might want to inspect the data itself, using Excel or a text editor.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
