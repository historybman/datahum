{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Applying Dunning's log-likelihood to 19c poetry\n",
    "\n",
    "I've put my \"solutions\" to in-class exercises on the Moodle, except for Exercise 2, which has become our homework assignment. \n",
    "\n",
    "## Problem 1.\n",
    "\n",
    "Find 25 words that are overrepresented in poetry reviewed by elite 19c magazines, as compared to other works of poetry that didn't get reviewed in those venues. Also list 25 words that are overrepresented in poetry that didn't get reviewed.\n",
    "\n",
    "To do this, you'll need to copy over some of the functions from our Week 4 exercises, and also copy over the code from our in-class Exercise #1, editing it so that it divides the corpus.\n",
    "\n",
    "Here's some code to get us started. I load some modules we're likely to need, and then load the ```poefic``` corpus.\n",
    "\n",
    "Then I filter the ```poefic``` DataFrame to have only poetry. I'm doing this for two reasons. The first is that I'm a little concerned that the size of the data is posing a problem on some computers. The other, more immediate, reason is that this dataset only has an even distribution of the \"reception\" variable in poetry. (Almost all the fiction I gave you was reviewed in elite venues.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/rmorriss/Documents/datahum/code\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>reception</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1835</td>\n",
       "      <td>Browning, Robert,</td>\n",
       "      <td>Paracelsus</td>\n",
       "      <td>poetry</td>\n",
       "      <td>remove</td>\n",
       "      <td>Paracelsus. We 154 PARACELSUS [BOOK III Not ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1833</td>\n",
       "      <td>Browning, Robert,</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>poetry</td>\n",
       "      <td>remove</td>\n",
       "      <td>all, I sought How best life’s end might be att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1855</td>\n",
       "      <td>Arnold, Matthew,</td>\n",
       "      <td>Poems</td>\n",
       "      <td>poetry</td>\n",
       "      <td>elite</td>\n",
       "      <td>grace, and Wisdom be too proud To halve a lodg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1867</td>\n",
       "      <td>Arnold, Matthew,</td>\n",
       "      <td>New poems</td>\n",
       "      <td>poetry</td>\n",
       "      <td>elite</td>\n",
       "      <td>from the West was then in shade. Ah ! now 'tis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1861</td>\n",
       "      <td>Mangum, A. W.</td>\n",
       "      <td>The holy shield</td>\n",
       "      <td>poetry</td>\n",
       "      <td>vulgar</td>\n",
       "      <td>happy hgme which he had exchange d for the ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1889</td>\n",
       "      <td>Hopkins, Gerard Manley</td>\n",
       "      <td>Poems of Gerard Manley Hopkins</td>\n",
       "      <td>poetry</td>\n",
       "      <td>addcanon</td>\n",
       "      <td>Randal; How far from then forethought of, all ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date                  author                           title   genre  \\\n",
       "0  1835       Browning, Robert,                      Paracelsus  poetry   \n",
       "1  1833       Browning, Robert,                         Pauline  poetry   \n",
       "2  1855        Arnold, Matthew,                           Poems  poetry   \n",
       "3  1867        Arnold, Matthew,                       New poems  poetry   \n",
       "4  1861           Mangum, A. W.                 The holy shield  poetry   \n",
       "5  1889  Hopkins, Gerard Manley  Poems of Gerard Manley Hopkins  poetry   \n",
       "\n",
       "  reception                                               text  \n",
       "0    remove  Paracelsus. We 154 PARACELSUS [BOOK III Not ea...  \n",
       "1    remove  all, I sought How best life’s end might be att...  \n",
       "2     elite  grace, and Wisdom be too proud To halve a lodg...  \n",
       "3     elite  from the West was then in shade. Ah ! now 'tis...  \n",
       "4    vulgar  happy hgme which he had exchange d for the ten...  \n",
       "5  addcanon  Randal; How far from then forethought of, all ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, csv, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print('Current working directory: ' + cwd + '\\n')\n",
    "      \n",
    "relativepath = os.path.join('..', 'data', 'weekfour', 'poefic.csv')\n",
    "poefic = pd.read_csv(relativepath)\n",
    "\n",
    "# FILTERING BY ROW TO GET ONLY THE POETRY\n",
    "poefic = poefic[poefic['genre'] == 'poetry']\n",
    "# equivalent to\n",
    "    # poefic = poefic.loc[poefic['genre] == poetry, : ]\n",
    "poefic.index = range(poefic.shape[0])\n",
    "poefic.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A small digression about the code above**\n",
    "\n",
    "It's worth dwelling for a moment on the statement that does filtering by row. Notice that if you index a pandas DataFrame with a single string, like ```poefic['genre']```, you get a column. But if you generate a series of Boolean values, and use *that* to index the DataFrame, like so,\n",
    "\n",
    "```poefic[poefic['genre'] == 'poetry']```\n",
    "\n",
    "You'll be selecting *rows* where the series has a value ```True.```\n",
    "\n",
    "If it's not clear what I mean by \"generating a series of Boolean values,\" look at the result of the cell below. (You can delete the cell below when you're working on the homework; this is all a digression.) Notice also, in the code above, that you can also use the ```.loc``` method to specify rows and columns at the same time if you want to. In this case I haven't specified a column for ```.loc``` to select, the ``` : ``` after the comma is a way of saying \"all the columns.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This explanation makes very good sense!  Thanks Ted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3     True\n",
       "4    False\n",
       "Name: reception, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elite = poefic['reception'] == 'elite'\n",
    "elite[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CODE FOR PROBLEM 1\n",
    "\n",
    "# You'll need to copy over the functions you need: things like \"tokenize\" will \n",
    "# certainly be necessary.\n",
    "\n",
    "# I recommend removing stopwords, but test, and see what happens if you don't.\n",
    "\n",
    "# The column 'reception' has several possible values, including 'elite' (was\n",
    "# reviewed in elite journals), and 'vulgar' (which doesn't mean the poetry was\n",
    "# obscene, but is just a wry way of saying it didn't turn up in our sample of \n",
    "# reviews). You want to contrast these two groups. Leave out other rows, where\n",
    "# 'reception' has a value like 'remove.'\n",
    "\n",
    "# After you've run code to produce the top 25 and bottom 25 words, sorted by \n",
    "# signed Dunnings, write a few sentences of commentary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(astring):\n",
    "    ''' Breaks a string into words, and counts them.\n",
    "    Designed so it strips punctuation and lowercases everything,\n",
    "    but doesn't separate hashtags and at-signs.\n",
    "    '''\n",
    "    wordcounts = Counter()\n",
    "    # create a counter to hold the counts\n",
    "    \n",
    "    tokens = astring.split()\n",
    "    for t in tokens:\n",
    "        word = t.strip(',.!?:;-—()<>[]/\"\\'').lower()\n",
    "        wordcounts[word] += 1\n",
    "        \n",
    "    return wordcounts\n",
    "\n",
    "def addcounters(counter2add, countersum):\n",
    "    ''' Adds all the counts in counter2add to countersum.\n",
    "    Because Counters(like dictionaries) are mutable, it\n",
    "    doesn't need to return anything.\n",
    "    '''\n",
    "    \n",
    "    for key, value in counter2add.items():\n",
    "        countersum[key] += value\n",
    "\n",
    "def create_vocab(seq_of_strings, n):\n",
    "    ''' Given a sequence of text snippets, this function\n",
    "    returns the n most common words. We'll use this to\n",
    "    create a limited 'vocabulary'.\n",
    "    '''\n",
    "    vocab = Counter()\n",
    "    for astring in seq_of_strings:\n",
    "        counts = tokenize(astring)\n",
    "        addcounters(counts, vocab)\n",
    "    topn = [x[0] for x in vocab.most_common(n)]\n",
    "    return topn\n",
    "\n",
    "# a set of common words is often useful\n",
    "stopwords = {'a', 'an', 'are', 'and', 'but', 'or', 'that', 'this', 'so', \n",
    "             'all', 'at', 'if', 'in', 'i', 'is', 'was', 'by', 'of', 'to', \n",
    "             'the', 'be', 'you', 'were'}\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First things first: create a vocab!\n",
    "Like in the Trump exercise, we begin by creating a vocabulary of the poems. First we put the text of the poems into a variable called `poems_text`.  Next we pass `poems_text` to the `create_vocab` function, and put the result in a variable called `poem_vocab`.  This gives us a pandas SERIES, from which we can pull out the stop words.  The result is a SERIES which we can treat as a list and print the first 20 words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'wanton',\n",
       " 'forever',\n",
       " '24',\n",
       " 'regal',\n",
       " 'kindling',\n",
       " 'unfurled',\n",
       " 'flies',\n",
       " 'pleasures',\n",
       " 'sake']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_text = poefic['text']\n",
    "poem_vocab = create_vocab(poems_text, 5000)\n",
    "poem_vocab = list(set(poem_vocab)- stopwords)\n",
    "poem_vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next step: divide the poems by reception\n",
    "Great! I will say that this is a weird list of words; not exactly what I'd expect to be the top 10words in the vocab of this batch of poems.  In any case, now we need to classify our poems into their groups. In the case of the Trump exercise, the variable that we used to divide the tweets was the origin of the tweets: iphone vs. android.  In this case, we will divide the poems by the values in the reception column.  One group, `elite`, will be those reviewed in elite journals.  The other group will be `vulgar`, and it is the group not reviewed in those journals.\n",
    "\n",
    "The method is to make a counter for `elite` and one for `vulgar`.  Then figure out the number of rows in our data frame `poefic` and use this to write a for loop (using the range function) that will cycle through the dataframe and pick out the poetry text in each category, then cycle through and add its tokens to the counters that we initiated.  In the end, we'll have two counters corresponding to the two groups.\n",
    "\n",
    "I will paste in the functions here first, and then move to assemble the loops and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP VALUES:\n",
      "two thousand 2000\n",
      "ten 10\n",
      "\n",
      "BOTTOM VALUES:\n",
      "neg one -1\n",
      "zero 0\n"
     ]
    }
   ],
   "source": [
    "def logodds(countsA, countsB, word):\n",
    "    ''' Straightforward.\n",
    "    '''\n",
    "    \n",
    "    odds = (countsA[word] + 1) / (countsB[word] + 1)\n",
    "    \n",
    "    # Why do we add 1 on both sides? Two reasons. The hacky one is \n",
    "    # that otherwise we'll get a division-by-zero error whenever\n",
    "    # word isn't present in countsB. The more principled reason\n",
    "    # is that this technique (called Laplacian smoothing) tends\n",
    "    # to reduce the dramatic disproportion likely to be found in\n",
    "    # very rare words.\n",
    "    \n",
    "    return math.log(odds)\n",
    "\n",
    "def signed_dunnings(countsA, totalA, countsB, totalB, word):\n",
    "    ''' Less straightforward. This function calculates a signed (+1 / -1)\n",
    "    version of Dunning's log likelihood. Intuitively, this is a number \n",
    "    that gets larger as the frequency of the word in our two corpora\n",
    "    diverges from its EXPECTED frequency -- i.e., the frequency it would\n",
    "    have if it were equally distributed over both. But it also tends to get\n",
    "    larger as the raw frequency of the word increases.\n",
    "    \n",
    "    Note that this function requires two additional arguments:\n",
    "    the total number of words in A and B. We could calculate that inside\n",
    "    the function, but it's faster to calculate it just once, outside the function.\n",
    "    \n",
    "    Also note: the strict definition of Dunnings has no 'sign': it gets bigger\n",
    "    whether a word is overrepresented in A or B. I've edited that so that Dunnings\n",
    "    is positive if overrepresented in A, and negative if overrepresented in B.\n",
    "    '''\n",
    "    if word not in countsA and word not in countsB:\n",
    "        return 0\n",
    "    \n",
    "    # the raw frequencies of this word in our two corpora\n",
    "    # still doing a little Laplacian smoothing here\n",
    "    a = countsA[word] + 0.1\n",
    "    b = countsB[word] + 0.1\n",
    "    \n",
    "    # now let's calculate the expected number of times this\n",
    "    # word would occur in both if the frequency were constant\n",
    "    # across both\n",
    "    overallfreq = (a + b) / (totalA + totalB)\n",
    "    expectedA = totalA * overallfreq\n",
    "    expectedB = totalB * overallfreq\n",
    "    \n",
    "    # and now the Dunning's formula\n",
    "    dunning = 2 * ((a * math.log(a / expectedA)) + (b * math.log(b / expectedB)))\n",
    "    \n",
    "    if a < expectedA:\n",
    "        return -dunning\n",
    "    else:   \n",
    "        return dunning\n",
    "\n",
    "# a set of common words is often useful\n",
    "stopwords = {'a', 'an', 'are', 'and', 'but', 'or', 'that', 'this', 'so', \n",
    "             'all', 'at', 'if', 'in', 'i', 'is', 'was', 'by', 'of', 'to', \n",
    "             'the', 'be', 'you', 'were'}\n",
    "\n",
    "# finally, one more function: given a list of tuples like\n",
    "testlist = [(10, 'ten'), (2000, 'two thousand'), (0, 'zero'), (-1, 'neg one'), (8, 'eight')]\n",
    "# we're going to want to sort them and print the top n and bottom n\n",
    "\n",
    "def headandtail(tuplelist, n):\n",
    "    tuplelist.sort(reverse = True)\n",
    "    print(\"TOP VALUES:\")\n",
    "    for i in range(n):\n",
    "        print(tuplelist[i][1], tuplelist[i][0])\n",
    "    \n",
    "    print()\n",
    "    print(\"BOTTOM VALUES:\")\n",
    "    lastindex = len(tuplelist) - 1\n",
    "    for i in range(lastindex, lastindex - n, -1):\n",
    "        print(tuplelist[i][1], tuplelist[i][0])\n",
    "        \n",
    "headandtail(testlist, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n",
      "TOP VALUES:\n",
      "isis 3.5263605246161616\n",
      "osiris 3.367295829986474\n",
      "typhon 3.091042453358316\n",
      "eleanore 3.044522437723423\n",
      "lilac 2.9444389791664403\n",
      "gareth 2.9444389791664403\n",
      "dauber 2.9444389791664403\n",
      "julian 2.772588722239781\n",
      "hech 2.70805020110221\n",
      "handsomest 2.70805020110221\n",
      "wonted 2.6390573296152584\n",
      "pazon 2.6390573296152584\n",
      "muza 2.6390573296152584\n",
      "budget 2.6390573296152584\n",
      "jane 2.3978952727983707\n",
      "tragedy 2.2512917986064953\n",
      "jules 2.1972245773362196\n",
      "willie 2.0794415416798357\n",
      "ida 2.0794415416798357\n",
      "saladin 2.0149030205422647\n",
      "\n",
      "BOTTOM VALUES:\n",
      "rosamond -3.044522437723423\n",
      "laura -2.995732273553991\n",
      "herodias -2.9444389791664407\n",
      "emma -2.8622008809294686\n",
      "mornia's -2.833213344056216\n",
      "apache -2.772588722239781\n",
      "aulus -2.70805020110221\n",
      "diuk -2.70805020110221\n",
      "santaclaus -2.70805020110221\n",
      "lyteria -2.639057329615259\n",
      "philomel -2.4849066497880004\n",
      "driver -2.3978952727983707\n",
      "journal -2.3025850929940455\n",
      "fo -2.1400661634962708\n",
      "ting -2.1400661634962708\n",
      "ar -2.0794415416798357\n",
      "cain -2.0794415416798357\n",
      "pounds -2.0794415416798357\n",
      "would'st -2.0149030205422647\n",
      "pleasure's -1.9459101490553135\n"
     ]
    }
   ],
   "source": [
    "elite = Counter()\n",
    "vulgar = Counter()\n",
    "\n",
    "# numrows = len(poefic['text'])\n",
    "numrows = poefic.shape[0]\n",
    "print(numrows)\n",
    "\n",
    "# Now write the for loop:\n",
    "\n",
    "poefic['text'][0]\n",
    "for i in range(numrows):\n",
    "    counts = tokenize(poefic['text'][i])\n",
    "    if poefic['reception'][i] == 'elite':\n",
    "        addcounters(counts, elite)\n",
    "    elif poefic['reception'][i] == 'vulgar':\n",
    "        addcounters(counts, vulgar)\n",
    "\n",
    "# Now sum up the values in the counters, which are necessary for the division in the formula.\n",
    "\n",
    "vulgar_sum = sum(vulgar.values())\n",
    "elite_sum = sum(elite.values())\n",
    "\n",
    "# Now write the loop that iterates over the words in `poem_vocab` and passes them into the functions ```logodds``` \n",
    "# and then the ```signed_dunning```\n",
    "\n",
    "tuplelist = []\n",
    "\n",
    "for word in poem_vocab:\n",
    "    g = logodds(elite, vulgar, word)\n",
    "#     g = signed_dunnings(elite, elite_sum, vulgar, vulgar_sum, word)\n",
    "    tuplelist.append((g, word))\n",
    "\n",
    "headandtail(tuplelist, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief commentary on results.\n",
    "\n",
    "This isn't a class on 19th-century poetry, so I don't expect you to fully\n",
    "interpret the results. (As Clarice was rightly suggesting in class, it's\n",
    "necessary to actually read a few documents before we're in a position to\n",
    "interpret quantitative patterns.) But you might be able to speculate or\n",
    "form tentative hypotheses based on a selection of distinctive words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Interesting Results\n",
    "I'm so relieved to get the code working after struggling to write that loop last night (I was hung up for 45 minutes because the indexing wasn't working on poefic!-- thanks for the tip).  Now that it works, I'm looking at the results of the signed dunning.  The way I set it up, the words with positive values are the most disproportionately common (or overrepresented) words in the class `elite`, which is to say that they are the most overrepreesnted  words in the poems that were reviewed in elite literary journals.  The words in the second list, the ones with the negative scores, are those words most disproportionately common in poetry not reviewed in elite literary journals.  I'm not sure quite how to characterize the difference between these lists; it seems fair to say that the \"elite\" poetry has a kind of \"ROMANTIC\" flavor to it-- Egyptian myth, grey, feminine pronouns and names.  The vulgar poetry list contains religious/ Christian motifs, first person plural pronouns.  Not sure what to say.  \n",
    "\n",
    "Interestingly the logodds function turns up some of the same patterns, but not all. Whatever the differences, though, the same dilemma presents with the results of the logodds: it's hard to interpret what the separation here represents.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
